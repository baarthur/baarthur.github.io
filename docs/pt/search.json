[
  {
    "objectID": "posts/2023-06-20-basedosdados/index.html",
    "href": "posts/2023-06-20-basedosdados/index.html",
    "title": "Acessando a Base dos Dados no R",
    "section": "",
    "text": "A Base dos Dados é uma platadorma excelente para obter dados oficiais e tratados de forma conveniente. Podemos baixá-la direto no R com facilidade, basta prestarmos atenção a algumas etapas.\nEsta é uma rotina simplificada. Veja mais no Workshop: Aprenda a acessar dados públicos em R, da Base dos Dados."
  },
  {
    "objectID": "posts/2023-06-20-basedosdados/index.html#introdução",
    "href": "posts/2023-06-20-basedosdados/index.html#introdução",
    "title": "Acessando a Base dos Dados no R",
    "section": "",
    "text": "A Base dos Dados é uma platadorma excelente para obter dados oficiais e tratados de forma conveniente. Podemos baixá-la direto no R com facilidade, basta prestarmos atenção a algumas etapas.\nEsta é uma rotina simplificada. Veja mais no Workshop: Aprenda a acessar dados públicos em R, da Base dos Dados."
  },
  {
    "objectID": "posts/2023-06-20-basedosdados/index.html#primeiros-passos",
    "href": "posts/2023-06-20-basedosdados/index.html#primeiros-passos",
    "title": "Acessando a Base dos Dados no R",
    "section": "Primeiros passos",
    "text": "Primeiros passos\nSempre que for trabalhar em um novo projeto, aproveite as funcionalidades do R Studio. Vá em File &gt; New Project... &gt; New Directory ou Existing Directory. Segundo passo: criar um arquivo para a rotina (File &gt; New File... &gt; ...). Pode ser um R Script, um R Markdown ou um Quarto Markdown (recomendo este último).\n\n\n\n\n\n\n\n\n\n\nUse pastas diferentes dentro da sua pasta do projeto para organizar seus arquivos. Eu uso três pastas; data, src e output: a primeira para as bases de dados, a segunda para os códigos e a terceira para PDFs, gráficos e outras produções.\n\n\nCrie um bloco de código (Ctrl + Alt + I) para chamar os pacotes necessários. Use a opção #| label: setup, como abaixo, para ele sempre ser executado no começo.\n\n```{r}\n#| label: setup\n\n# geral e tratamento de dados\nlibrary(here)\nlibrary(tidyverse)\n\n# bases de dados\nlibrary(basedosdados)\n```\n\n\nGoogle Cloud\nPara baixar os dados no R, vamos precisar criar um projeto no Google Cloud. Os projetos do Google Cloud são muito usados em diversas situações (ex.: APIs do Google Maps) e a Google nos dá um limite gratuito (1 TB por dia ou 200 dólares por mês): mas não se preocupe, você não vai estourar essa cota.\n\nVá até cloud.google.com/\nClique em Console (canto superior direito)\nNa caixa de diálogo (vide abaixo), concorde e continue\n\n\n\nEm seguida, clique em Selecione um projeto &gt; NOVO PROJETO\nDê um nome ao projeto. Esse nome não pode ser alterado depois.\n\n\n\nApós criar o seu projeto, você será direcionado à página do projeto. Agora, é só configurar as funções do pacote {basedosdados} no R para acessar o seu projeto.\n\n\n\nBase dos dados\nVamos chamar a função set_billing_id(). Dentro dela, você vai inserir o ID do seu projeto (entre aspas, porque é um character), disponível aqui:\n\n\n\n\n\n\n\n\n\n\n\nO seu ID do projeto é pessoal. Não compartilhe com ninguém, ou disponibilize na internet, ou você corre o risco de ganhar uma fatura nada amigável no seu cartão de crédito.\n\n\n\n```{r}\n#| label: config-bd\n\nset_billing_id(\"id-projeto\")\n```\n\nVocê deve ver a mensagem “Project keys set successfully”."
  },
  {
    "objectID": "posts/2023-06-20-basedosdados/index.html#chamada-sql",
    "href": "posts/2023-06-20-basedosdados/index.html#chamada-sql",
    "title": "Acessando a Base dos Dados no R",
    "section": "Chamada SQL",
    "text": "Chamada SQL\nA melhor forma de baixar dados da BD pelo R é fazendo uma chamada SQL (lê-se “síquel” ou sequel). SQL é uma linguagem de pesquisa, muito usada para acessar base dos dados. Mas não se preocupe, não precisamos dominar SQL! Basta aprender a estrutura básica.\n\nQuery: sintaxe básica\nNa página da base que você pretende baixar (ex.: PNAD Contínua), copie o código que está na aba SQL: ele é a sua query, que você vai usar para requisitar uma informação. Você vai criar um objeto no R para guardá-la.\nObserve que a query tem a seguinte estrutura &gt; SELECT * FROM `basedosdados.br_ibge_pnadc.microdados` LIMIT 100\nVamos entendê-la:\n\nSELECT indica as variáveis que vamos selecionar. Como essa informação é seguida de um asterisco, indica que vamos selecionar todas as variáveis da base. Para selecionar variáveis:\n\nSelecione uma das tabelas tratadas no menu lateral esquerdo.\nDesça até colunas: ali você encontra o nome das variáveis, seu formato e uma descrição.\nSepare os nomes das variáveis por vírgulas após SELECT (apague o asterisco)\n\nFROM `basedosdados.br_ibge_pnadc.microdados`: o endereço de onde os dados virão.\nLIMIT 100 significa que estamos limitando a baixar apenas as 100 primeiras linhas.\n\nAo baixar microdados do Censo, da Rais ou da Pnad, estamos lidando com um volume gigante de informações. Por isso, é recomendável usar a opção LIMIT 100, LIMIT 1000 etc para baixar só um pedaço e testar se você vai querer mesmo essa base (por exemplo, investigar se as variáveis te atendem).\nQuando você já tiver certeza de que vai usar essa base, tire o LIMIT XXX, mas atenção: é extremamente recomendável que você selecione uma lista de variáveis em vez de baixar todas. Isso vai poupar não apenas sua internet e o espaço no seu disco, mas também a eficiência do R quando for ler e trabalhar nos seus dados.\nExemplo: vamos pegar algumas informações da PNAD de domicílios.\n\n```{r}\n#| label: query-1\n\nquery_pnad &lt;- \"SELECT ano, id_domicilio, id_uf, id_upa, V1028, V2007, V2010, V3001, V4009, V4012, VD3005 VD4032 FROM basedosdados.br_ibge_pnadc.microdados LIMIT 100\"\n```\n\nPodemos melhorar a query ainda mais aprendendo mais três argumentos: WHERE, AND, OR e in. Eles nos ajudam a filtrar a base para, por exemplo, baixar dados só de um estado, de anos específicos ou uma combinação disso tudo. Isso facilita muito a nossa vida, porque assim evitamos baixar um monte de dados desnecessários.\nExemplo: atualizar a query anterior para pegar apenas dados de 2017 a 2021 de Minas Gerais. Para isso, vamos usar um pouco de lógica para montar a sintaxe:\n\nWHERE indica os filtros a serem aplicados. No caso, sigla_uf='MG' é o filtro do estado.\nO filtro do ano é mais complicado. Temos duas alternativas:\n\nano = 2017 OR ano = 2019 OR ano = 2021. Muito repetitivo!\nMelhor: ano in (2017,2019,2021).\n\nAgora, como queremos dados de MG E nessa janela temporal, concatenamos os dois com AND:\n\nSELECT (...) WHERE sigla_uf='MG' AND (ano in (2017,2019,2021))\nColocamos a cláusula do ano dentro de parênteses para garantir que tudo aquilo será avaliado. Isso é importante, por exemplo, quando estivermos trabalhando com cláusulas OR em conjunto, senão vira bagunça.\n\n\n\n\n\n\n\n\n\n\n\n\nA sua query é um vetor entre aspas no R. Assim, se você estiver filtrando uma variável que é character, você pode acabar estragando sua query se não tomar cuidado. Por isso, use aspas duplas (\") para a query e aspas simples (') para os characters dentro da query, como fizemos com sigla_uf='MG'.\n\n\n\n```{r}\n#| label: query-2\n\nquery_pnad &lt;- \"SELECT ano, id_domicilio, id_uf, id_upa, V1028, V2007, V2010, V3001, V4009, V4012, VD3005 VD4032 FROM basedosdados.br_ibge_pnadc.microdados WHERE sigla_uf='MG' AND ano in (2017,2019,2021) LIMIT 100\"\n```\n\nJá está bom, mas essa query está difícil de ler. Podemos separar cada bloco dela em objetos diferentes. depois concatenar tudo em um objeto só usando paste():\n\n```{r}\n#| label: query-3\n\nvariables &lt;- \"ano, id_domicilio, id_uf, id_upa, V1028, V2007, V2010, V3001, V4009, V4012, VD3005 VD4032\"\nsource &lt;- \"`basedosdados.br_ibge_pnadc.microdados`\"\nclause_where &lt;- \"sigla_uf='MG'\"\nclause_and_ano &lt;- \"(ano in (2017,2019,2021))\"\n\n### query: PNAD MG 2017-2021\nquery_pnad_1721 &lt;- paste(\n  \"SELECT\", variables,\n  \"FROM\", source, \n  \"WHERE\", clause_where,\n  \"AND\", clause_and_ano,\n  \"LIMIT 100\"\n)\n```\n\nEssa estrutura é útil porque permite facilmente modificar trechos evitando erros e reproduzir em outros trabalhos mantendo uma sintaxe padronizada e eficiente. Outra dica: você pode modificar a query comentando linhas do seu vetor, como no exemplo abaixo (tirar o LIMIT e baixar tudo).\n\n```{r}\n#| label: query-4\n\n### query: PNAD MG 2017-2021\nquery_pnad_1721 &lt;- paste(\n  \"SELECT\", variables,\n  \"FROM\", source, \n  \"WHERE\", clause_where,\n  \"AND\", clause_and_ano,\n  \"LIMIT 100\"\n)\n```\n\n\n\nBaixar a query\nAgora, podemos baixar a query. Podemos fazer isso de duas formas: salvando em um objeto do R ou salvando em um .csv no computador. Eu prefiro a segunda opção, porque permite carregar os dados depois sem ter que baixar tudo de novo. Na hora de baixar os dados, vai aparecer uma opção no console do R pedindo para autenticar o usuário no seu navegador (ou digite 2, se o seu email já aparecer) e prossiga.\n\n\n\n\n\n\n\n\n\n\nVocê deve selecionar todas as caixas, como na imagem abaixo.\n\n\n\nOpção 1: direto no R\nNesse caso, usamos a função read_sql()\n\n```{r}\n#| label: download-query-R\n\ndf_pnad &lt;- read_sql(query_pnad_1721)\n```\n\nOpção 2: salvar no disco\nPara isso, usamos a função download() e incluímos na chamada o argumento path com o caminho para salvar. Como estamos usando um R Project, passamos o diretório relativo à pasta do projeto. Ou seja: não precisa de inverter barras e pegar o caminho completo da pasta. No caso de usar RMarkdown ou Quarto (meu caso) em vez de um R Script, usamos a função here() também.\nNo exemplo abaixo, vamos salvar a base dos dados na pasta data dentro da pasta do projeto (não se esqueça de criar a pasta).\n\n```{r}\n#| label: download-query\n\ndownload(query_pnad_1721, path = here(\"data/df_pnad_mg_1721.csv\"))\n```\n\nPronto! Agora já podemos carregar, tratar e analisar os dados:\n\n```{r}\n#| label: load-bd\n\ndf_pnad &lt;- read_csv(here(\"data/df_pnad_mg_1721.csv\"))\n```"
  },
  {
    "objectID": "posts/2023-11-05-mapchallenge/index.html",
    "href": "posts/2023-11-05-mapchallenge/index.html",
    "title": "30 day Map Challenge 2023",
    "section": "",
    "text": "I have known the 30 day map challenge for two years now, but I was always too shy to join it. But the whole point is to have fun and learn something along the way, so here I am! I will update this post daily with my maps and the link to the code on my github repo. I missed the first two days, so I’m starting from day 3."
  },
  {
    "objectID": "posts/2023-11-05-mapchallenge/index.html#day-three-polygons",
    "href": "posts/2023-11-05-mapchallenge/index.html#day-three-polygons",
    "title": "30 day Map Challenge 2023",
    "section": "Day three: polygons",
    "text": "Day three: polygons\nI spent some five hours making this, and I sadly lost my original code because I was stupid enought to not save the file. Accidents happen, so always save your files! Fortunately, I was at a loose end enough to recreate it.\nThe inspiration for this came from this tweet from @_palenrique, where he compared Brazil’s Federal District size to other huge metropolitan areas.\n\nThe biggest challenge was how to get all metropolitan areas in the same scale. I had a notion that I should use coord_sf() in my ggplot to make them all in the same frame, but I just did not know how to get a bounding box with the same widths for the different regions. Then I had an idea: what if I calculate a buffer from the region’s centroid to the bounding box limit and use this constant ratio to create a buffer & a bounding box for each city?\n\nAnyways, here it is!\n\nFork me on GitHub: https://github.com/baarthur/mapchallenge-2023/blob/main/src/3-polygons.qmd\n\n\nThis version is actually a little better than the original one, which you can still find on twitter."
  },
  {
    "objectID": "posts/2023-11-05-mapchallenge/index.html#day-four-a-bad-map",
    "href": "posts/2023-11-05-mapchallenge/index.html#day-four-a-bad-map",
    "title": "30 day Map Challenge 2023",
    "section": "Day four: a bad map!",
    "text": "Day four: a bad map!\nWhenever I think of a bad map, three things come to my mind: clumsy information, bad colors, and the amazing @TerribleMaps twitter page. Then I thought, what can be both totally useful and disturbing at the same time? The answer was on my face: I’ve always been fascinated by how my home state of Minas Gerais looks like a face with a big nose and booger coming out of it, so I manually created a list of cities for each feature and ggploted it.\n\nFork me on GitHub: https://github.com/baarthur/mapchallenge-2023/blob/main/src/4-bad_map.qmd\n\n\nLater on, I found out that gaga stans really liked it. I had no idea they had an internal joke about her!"
  },
  {
    "objectID": "posts/2023-11-05-mapchallenge/index.html#day-five-an-analog-map",
    "href": "posts/2023-11-05-mapchallenge/index.html#day-five-an-analog-map",
    "title": "30 day Map Challenge 2023",
    "section": "Day five: an analog map",
    "text": "Day five: an analog map\nOkay, I’m assuming this means I use no digital thing to make this, am I right? Since a kid/pre-teen I have always loved to draw maps, especially during boring classes in school. So that’s what I did, but this time using fountain pains!\nI tried it five times before my final version. I ended up starting by Minas Gerais… And it says a lot that Minas is bigger than Amazonas on my map! Perhaps we increase the things we have a better grasp. I’m so used to Minas and the Southeast that all I can say is sorry for my terrible borders. At least I got all states and capitals right…"
  },
  {
    "objectID": "posts/2023-11-05-mapchallenge/index.html#day-six-asia",
    "href": "posts/2023-11-05-mapchallenge/index.html#day-six-asia",
    "title": "30 day Map Challenge 2023",
    "section": "Day six: Asia",
    "text": "Day six: Asia\nSo an Asia map… What can i do that’s still related to what I know? Also, I’m very tired. So I just looked for trade values for 1997 and 2022 to see how imports & exports evolved between time and between countries. The scale was a hell of a nightmare as always, but I think this looks quite okay!\n\nFork me on GitHub: https://github.com/baarthur/mapchallenge-2023/blob/main/src/6-asia.qmd"
  },
  {
    "objectID": "posts/2023-06-21-rotina-spatial/index.html",
    "href": "posts/2023-06-21-rotina-spatial/index.html",
    "title": "Rotina espacial no R",
    "section": "",
    "text": "Muitos amigos me perguntam como fazer operações espaciais no R. Então, decidi criar essa rotina muito simples, com o mínimo para começar e algumas operações básicas.\nComo eu já disse no post sobre a Base dos Dados: crie um R Project e seja organizado, ajude o você de amanhã! Ele vai agradecer.\n\n\n\nA melhor referência que eu conheço para dados espaciais no R: O livro Geocomputation With R.\nLivro em português lançado recentemente. Ainda não tive oportunidade de ler, mas parece muito bom!\n\nCartografia Temática em R para estudantes de Geografia\n\nExcelentes tutoriais também no r-spatial.org\ngeobr: mapas brasileiros em alta qualidade no R!\naopdata: Projeto Acesso a Oportunidades do Ipea, com base muito rica para download direto no R.\nGeosampa: portal da Prefeitura de São Paulo com diversos dados geolocalizados\nBHMap e IDE Sistema: idem, para BH e o Governo de Minas\nMapbiomas: nunca usei, mas é referência para o pessoal que trabalha com meio ambiente.\nShapefiles de ferrovias, rodovias, aeroportos, portos e mais no site do ONTL/EPL"
  },
  {
    "objectID": "posts/2023-06-21-rotina-spatial/index.html#introdução",
    "href": "posts/2023-06-21-rotina-spatial/index.html#introdução",
    "title": "Rotina espacial no R",
    "section": "",
    "text": "Muitos amigos me perguntam como fazer operações espaciais no R. Então, decidi criar essa rotina muito simples, com o mínimo para começar e algumas operações básicas.\nComo eu já disse no post sobre a Base dos Dados: crie um R Project e seja organizado, ajude o você de amanhã! Ele vai agradecer.\n\n\n\nA melhor referência que eu conheço para dados espaciais no R: O livro Geocomputation With R.\nLivro em português lançado recentemente. Ainda não tive oportunidade de ler, mas parece muito bom!\n\nCartografia Temática em R para estudantes de Geografia\n\nExcelentes tutoriais também no r-spatial.org\ngeobr: mapas brasileiros em alta qualidade no R!\naopdata: Projeto Acesso a Oportunidades do Ipea, com base muito rica para download direto no R.\nGeosampa: portal da Prefeitura de São Paulo com diversos dados geolocalizados\nBHMap e IDE Sistema: idem, para BH e o Governo de Minas\nMapbiomas: nunca usei, mas é referência para o pessoal que trabalha com meio ambiente.\nShapefiles de ferrovias, rodovias, aeroportos, portos e mais no site do ONTL/EPL"
  },
  {
    "objectID": "posts/2023-06-21-rotina-spatial/index.html#setup",
    "href": "posts/2023-06-21-rotina-spatial/index.html#setup",
    "title": "Rotina espacial no R",
    "section": "Setup",
    "text": "Setup\nDefina um bloco de código (Ctrl + Alt + I) para chamar os pacotes necessários. Use a opção #| label: setup, como abaixo, para ele sempre ser executado no começo.\n\n```{r}\n#| label: setup\n#| results: hold\n\n# geral e tratamento de dados\nlibrary(here)\n```\n\nhere() starts at /Users/baarthur/Library/CloudStorage/OneDrive-Personal/Documentos/R/Projects/baarthur.github.io\n\n```{r}\n#| label: setup\n#| results: hold\n\nlibrary(janitor)\n```\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n```{r}\n#| label: setup\n#| results: hold\n\nlibrary(tidyverse)\n```\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n```{r}\n#| label: setup\n#| results: hold\n\n# operações espaciais\nlibrary(sf)\n```\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n```{r}\n#| label: setup\n#| results: hold\n\n# bases de dados\nlibrary(geobr)\nlibrary(sidrar)\n```"
  },
  {
    "objectID": "posts/2023-06-21-rotina-spatial/index.html#carregando-dados",
    "href": "posts/2023-06-21-rotina-spatial/index.html#carregando-dados",
    "title": "Rotina espacial no R",
    "section": "Carregando dados",
    "text": "Carregando dados\n\nDa internet\nVários shapefiles brasileiros estão disponíveis online. Alguns podem ser baixados direto no R, como o {geobr} e o {aopdata}. Nesse exemplo, vamos baixar o shapefile dos municípios mineiros usando o {geobr}:\n\n```{r}\n#| label: download-shp\n\nshp_mg_muni &lt;- read_municipality(\n  code_muni = \"MG\",\n  showProgress = FALSE\n)\n```\n\nUsing year 2010\n\n\nSegundo o manual da função read_municipality() (digite ?read_municipality no console ou vá em Help e digite o nome da função), podemos baixar só os municípios de um estado especificando o código do estado ou sua sigla em code_muni, ou ainda baixar apenas uma cidade especificando o seu código de 7 dígitos do IBGE.\nAdicionei, ainda, showProgress = FALSE para não mostrar o status do download enquanto baixa. Outra opção é simplified = FALSE para baixar o shapefile mais detalhado possível. Isso é muito mais pesado; na dúvida, não baixe.\n\nÀs vezes, um shapefile “dá pau” na hora de fazer as operações que vamos ver lá na frente. Se isso acontecer, use a transformação st_make_valid() para consertá-lo:\n\n\n```{r}\n#| label: make-valid\n\nshp_mg_muni &lt;- shp_mg_muni %&gt;% \n  st_make_valid()\n```\n\n\n\nDo computador\nNeste exemplo, vamos carregar dois shapefiles para fazer operações espaciais: a malha de municípios mineiros, no formato .shp, e um mapa ferroviário, no formato do Google Earth (.kml). Usando o pacote {sf}, carregamos os shapefiles com st_read(). Supondo que você tem uma pasta chamada shp dentro da pasta data com seus shapefiles:\n\n```{r}\n#| label: read-mg\n#| eval: false\n\nshp_mg_muni &lt;- here(\"data/shp/shapefile_minas.shp\") %&gt;% \n  st_read()\n```\n\n\n\n\n\n\n\n\n\n\n\nOs shapefiles do tipo .shp tem pelo menos quatro camadas, em arquivos separados: .dbf, .prj, .shp e .shx. Por mais que na função st_read() nós passemos só o .shp, ela está usando todas as camadas; logo, elas devem estar na pasta também!\n\n\n\n\nReading layer `Transmineiriana' from data source \n  `/Users/baarthur/Library/CloudStorage/OneDrive-Personal/Documentos/R/Projects/baarthur.github.io/posts/2023-06-21-rotina-spatial/data/shp/ferrovias.kml' \n  using driver `KML'\nSimple feature collection with 99 features and 2 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -48.2703 ymin: -23.51613 xmax: -38.40762 ymax: -12.49129\nGeodetic CRS:  WGS 84\n\n\n\n```{r}\n#| label: read-ferro\n#| eval: false\n\nshp_ferrovias &lt;- here(\"data/shp/ferrovias.kml\") %&gt;% \n  st_read()\n```\n\n\nNo Quarto (.qmd) e no RMarkdown (.Rmd), usamos a função here() do pacote homônimo para passar endereços relativos. Isso evita a bagunça que acontece com a dupla setwd()/getwd() e a chatice de ficar invertendo barras nos caminhos absolutos. Os endereços relativos são relativos à pasta origem do seu projeto, porque o R Project entende qur você está partindo dali.\n\n\n\nCompatibilidade de coordenadas\nExistem diferentes padrões de coordenadas (CRS, de Coordinate Reference System): o mais comum é o WGS 84, usado nos GPS e no Google Maps. Mas, como a terra não é plana, alguns padrões são mais adequados para locais diferentes. No Brasil, mapas administrativos costumam usar o Sirgas 2000 e suas variantes. Por isso, temos ficar atentos se nossos shapefiles estão no mesmo padrão! Para verificar:\n\n```{r}\n#| label: check-crs\n\nst_crs(shp_mg_muni)\nst_crs(shp_ferrovias)\n```\n\nCoordinate Reference System:\n  User input: SIRGAS 2000 \n  wkt:\nGEOGCRS[\"SIRGAS 2000\",\n    DATUM[\"Sistema de Referencia Geocentrico para las AmericaS 2000\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"Latin America - Central America and South America - onshore and offshore. Brazil - onshore and offshore.\"],\n        BBOX[-59.87,-122.19,32.72,-25.28]],\n    ID[\"EPSG\",4674]]\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nNesse exemplo, a malha municipal usa o Sirgas 2000, enquanto o mapa de ferrovias usa o WGS 84. Como eu prefiro o primeiro CRS, vou transformar o seguno para que também fique em Sirgas 2000.\n\n\n\n\n\n\n\n\n\n\nCada CRS tem um código EPSG associado. No caso do Sirgas 2000 é o 4674, e para o WGS 84, é o 4326. Veja mais em epsg.io.\n\n\n\n```{r}\n#| label: set-crs\n\n# Alternativa 1: modificar manualmente inserindo o CRS desejado.\nshp_ferrovias &lt;- shp_ferrovias %&gt;% \n  st_transform(crs = 4674)\n\n# Alternativa 2: modificar o CRS de X para que seja igual ao de Y.\nshp_ferrovias &lt;- shp_ferrovias %&gt;% \n  st_transform(crs = st_crs(shp_mg_muni))\n```"
  },
  {
    "objectID": "posts/2023-06-21-rotina-spatial/index.html#filtrar-shapefiles",
    "href": "posts/2023-06-21-rotina-spatial/index.html#filtrar-shapefiles",
    "title": "Rotina espacial no R",
    "section": "Filtrar shapefiles",
    "text": "Filtrar shapefiles\nSuponha que queremos filtrar as cidades que são atravessadas por algumas ferrovias. Podemos fazer isso com o st_filter(). Mas antes, um resumo sobre as operações espaciais:\nO pacte {sf} contém uma série de funções que computam relações topológicas entre objetos espaciais (da classe simple.feature). Por exemplo: st_intersects(x,y) indica se x cruza y; st_covers(x,y), se x cobre y e o contrário por st_covered_by(x,y) e assim em diante. Leia mais sobre essas operações no excelente livro do Robin Lovelace e no site do PostGIS, pois as operações realizadas em SQL são basicamente as mesmsas que o {sf} faz no R.\nEssas operações espaciais também podem ser usadas como predicado para filtrar ou juntar dados. Nesse exemplo, vamos usar o predicado st_intersects:\n\n```{r}\nshp_muni_ferro &lt;- shp_mg_muni %&gt;% \n  st_filter(shp_ferrovias, .predicate = st_intersects)\n```\n\nO novo objeto contém 190 municípios: apenas aqueles atravessados pelas ferrovias contidas no .kml. Alternativamente, podemos só salvar o novo objeto em cima do antigo: shp_mg_muni &lt;- shp_mg_muni %&gt;% (...)"
  },
  {
    "objectID": "posts/2023-06-21-rotina-spatial/index.html#combinar-bases",
    "href": "posts/2023-06-21-rotina-spatial/index.html#combinar-bases",
    "title": "Rotina espacial no R",
    "section": "Combinar bases",
    "text": "Combinar bases\nOutra operação poderosa no R é combinar informações de uma base com um shapefile. Nesse exemplo, vamos usar uma base de população municipal do IBGE para cruzar com o shapefile de cidades mineiras.\n\nBaixando dados do IBGE com o SidraR\nO Sidra —Sistema IBGE de Recuperação Automática— pode ser acessado diretamente pelo R. Você pode tanto buscar termos específicos, usando search_sidra(\"termo\"), quanto baixar diretamente uma tabela que você já conheça. Vamos usar o exemplo completo: vou buscar informações sobre população.\n\n```{r}\n#| label: search_sidra\n#| eval: false\n\nsearch_sidra(\"população\")\n```\n\nO resultado retornou mais de 90 tabelas. Como isso é muito confuso, prefiro ir no site do Sidra, ver a tabela que eu quero e baixar no R. No caso, quero a tabela 6579. Vamos ver as opções disponíveis para ela:\n\n```{r}\n#| label: info_sidra\n\ninfo_sidra(6579)\n```\n\n$table\n[1] \"Tabela 6579: População residente estimada\"\n\n$period\n[1] \"2001, 2002, 2003, 2004, 2005, 2006, 2008, 2009, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021\"\n\n$variable\n   cod                                   desc\n1 9324 População residente estimada (Pessoas)\n\n$classific_category\nNULL\n\n$geo\n     cod                      desc\n1 Brazil                Brasil (1)\n2 Region         Grande Região (5)\n3  State Unidade da Federação (27)\n4   City         Município (5.570)\n\n\nDe posse dessas informações, podemos configurar a chamada da função get_sidra():\n\n```{r}\n#| label: get_sidra\n\ndf_pop &lt;- get_sidra(\n  6579,\n  period = \"2021\",\n  geo = \"City\"\n)\n```\n\nConsidering all categories once 'classific' was set to 'all' (default)\n\n```{r}\n#| label: get_sidra\n\nglimpse(df_pop)\n```\n\nRows: 5,570\nColumns: 11\n$ `Nível Territorial (Código)` &lt;chr&gt; \"6\", \"6\", \"6\", \"6\", \"6\", \"6\", \"6\", \"6\", \"…\n$ `Nível Territorial`          &lt;chr&gt; \"Município\", \"Município\", \"Município\", \"M…\n$ `Unidade de Medida (Código)` &lt;chr&gt; \"45\", \"45\", \"45\", \"45\", \"45\", \"45\", \"45\",…\n$ `Unidade de Medida`          &lt;chr&gt; \"Pessoas\", \"Pessoas\", \"Pessoas\", \"Pessoas…\n$ Valor                        &lt;dbl&gt; 22516, 111148, 5067, 86416, 16088, 15213,…\n$ `Município (Código)`         &lt;chr&gt; \"1100015\", \"1100023\", \"1100031\", \"1100049…\n$ Município                    &lt;chr&gt; \"Alta Floresta D'Oeste - RO\", \"Ariquemes …\n$ `Ano (Código)`               &lt;chr&gt; \"2021\", \"2021\", \"2021\", \"2021\", \"2021\", \"…\n$ Ano                          &lt;chr&gt; \"2021\", \"2021\", \"2021\", \"2021\", \"2021\", \"…\n$ `Variável (Código)`          &lt;chr&gt; \"9324\", \"9324\", \"9324\", \"9324\", \"9324\", \"…\n$ Variável                     &lt;chr&gt; \"População residente estimada\", \"Populaçã…\n\n\nE assim, baixamos a população de 2021 para todos os municípios brasileiros. No entanto, essa tabela do IBGE não está organizada da melhor forma pra processamento no R. Podemos melhorar removendo as informações desnecessárias (select()) e limpando os nomes (clean_names() e rename()) para compatibilizar com a outra tabela.\n\n\n\n\n\n\n\n\n\n\nUse os mesmos nomes para variáveis comuns nos dois objetos. Não é obrigatório, mas facilita sua vida; caso contrário, tem que especificar qual variável de x é igual a qual variável de y para dar o join. Como o shapefile do {geobr} vem com nomes padronizados, vamos adotá-la e modificar a base do IBGE.\n\n\n\n```{r}\n#| label: tidy-data\n\n# passo 1: limpar nomes (tirar maiúsculas, espaços e outras complicações)\ndf_pop &lt;- df_pop %&gt;% \n  clean_names() \n\n# passo 2: remover o que não precismos e renomear. Fazemos isso tudo junto com transmute, na sintaxe novo_nome = nome_antigo\ndf_pop &lt;- df_pop %&gt;% \n  transmute(\n    pop = valor, code_muni = as.numeric(municipio_codigo),\n    year = as.numeric(ano)\n  )\n```\n\nAo usarmos transmute, estamos ao mesmo tempo renomeando as variáveis que querendo e removendo as que não estão ali. Note que também passei as.numeric() em code_muni e ano, pois estavam como character. No caso de code_muni, essa informação é numérica (numeric) na base do {geobr}, então ia dar erro no join; já no caso do ano, é porque facilita quando esse tipo de informação é numérica (por exemplo, para filtrar datas maiores do que x).\n\n\n\n\n\n\n\n\n\n\nA informação de nome do município frequentemente está diferente entre bases. Ex.: acentuação, hifens, etc. Para não dar erro, prefira SEMPRE usar o código em vez do nome; repare que até removi o nome da cidade e vou usar apenas o do {geobr}. Nesse caso, a base do IBGE tem a sigla do estado junto do nome do município, como “Abadia dos Dourados - MG”.\n\n\n\n\nJuntando: população e shapefile\nAgora é partir para o abraço. Vamos jogar as informações do IBGE no shapefile —ou vice-versa; nesse caso (não é sempre), a ordem não importa.\n\n```{r}\n#| label: join\n\nshp_mg_muni &lt;- shp_mg_muni %&gt;% \n  left_join(df_pop)\n```\n\nJoining with `by = join_by(code_muni)`"
  },
  {
    "objectID": "posts/2023-06-21-rotina-spatial/index.html#visualização",
    "href": "posts/2023-06-21-rotina-spatial/index.html#visualização",
    "title": "Rotina espacial no R",
    "section": "Visualização",
    "text": "Visualização\n\nMapa de municípios e população\nVamos plotar o mapa de Minas Gerais, colorindo de acordo com a população.\n\n```{r}\n#| label: basic-plot\n\nggplot() +\n  geom_sf(\n    data = shp_mg_muni,\n    aes(fill = pop)\n  )\n```\n\n\n\n\nPodemos customizar esse mapa adiconando camadas e capadas. As duas mais importantes: uma camada para a escala de cores do fill (preenchimento) e outra para o tema.\nExistem duas coleções de paletas muito famosas: Brewer e Viridis. A primeira tem cores mais “comuns”, mas a segunda dá um contraste muito bom. Abaixo, as paletas de cada coleção e a sintaxe (substitua XXX pelo tipo de aesthetic em uso: fill, color etc.)\n\nBrewer: https://r-graph-gallery.com/38-rcolorbrewers-palettes.html\n\nDiscreta: ggplot() + (...) + scale_XXX_brewer()\nCondtínua: ggplot() + (...) + scale_XXX_distiller()\nBinned: ggplot() + (...) + scale_XXX_fermenter()\n\nViridis: https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html\n\nDiscreta: ggplot() + (...) + scale_XXX_viridis_d()\nCondtínua: ggplot() + (...) + scale_XXX_viridis_c()\nBinned: ggplot() + (...) + scale_XXX_viridis_b()\n\n\nExemplo com viridis\n\n```{r}\n#| label: cool-plot-viridis\n\nggplot() +\n  geom_sf(\n    data = shp_mg_muni,\n    aes(fill = pop),\n    color = \"lightgrey\"\n  ) +\n  scale_fill_viridis_c(\n    option = \"magma\",\n    direction = -1,\n    name = \"População\", \n    labels = scales::comma_format(big.mark = \" \", decimal.mark = \",\")\n  ) +\n  labs(\n    title = \"População dos municípios mineiros em 2021\",\n    caption = \"Fonte: IBGE (2023)\"\n  ) +\n  theme_void()\n```\n\n\n\n\nExemplo com Brewer:\n\n```{r}\n#| label: cool-plot-brewer\n\nggplot() +\n  geom_sf(\n    data = shp_mg_muni,\n    aes(fill = pop),\n    color = \"lightgrey\"\n  ) +\n  scale_fill_distiller(\n    palette = \"YlGnBu\",\n    direction = 1,\n    name = \"População\", \n    labels = scales::comma_format(big.mark = \" \", decimal.mark = \",\")\n  ) +\n  labs(\n    title = \"População dos municípios mineiros em 2021\",\n    caption = \"Fonte: IBGE (2023)\"\n  ) +\n  theme_void()\n```\n\n\n\n\n\nMelhorando o mapa\nDe cara, eu acho que podemos melhorar esse mapa de duas formas:\n\nA escala não é muito útil. Temos só uma cidade com mais de 1 milhão de habitantes e só 4 com mais de 500 mil, então uma escala binned pode ser mais útil do que uma contínua.\nA às vezes os limites municipais mais poluem do que ajudam. Nesse caso, eu gosto de definir color = NA ou deixar color na mesma escala do fill.\n\n\nVai depender do tamanho da sua malha e da precisão dos shapefiles: se ficar um vazio esquisito entre um polígono e outro, unifique color e fill.\n\nPrimeiro, vamos definir os argumentos de scale_... do lado de fora, para aplicar no fill e no color de forma unificada e diminuir o risco de erro humano. Nesse processo, vamos definir os breaks meio no olho, mas se quiser você pode usar quantis. Escolhi os valores abaixo vendo o que ficava melhor no mapa, tentando criar um equilíbrio de forma que permita distinguir as disparidades regionais, mas sem prejudicar muito o conforto visual. Para usar quantis, é só usar em breaks a função quantile(x, probs = seq(0,1, p)) em que x é a variável sendo quantificada (no caso, pop) e definimos o vetor de probabilidades como sendo a sequência de 0 a 1 de p em p. Por exemplo: para quartis, p = 0,25; para decis, p = 0,10 e assim por diante.\n\n```{r}\n#| label: scale-args\n\nscale_args &lt;- list(\n  palette = \"YlGnBu\",\n    direction = 1,\n    name = \"População\", \n    labels = scales::comma_format(big.mark = \" \", decimal.mark = \",\"),\n    breaks = c(5000, 25000, 50000, 100000, 250000, 500000, 2500000)\n)\n```\n\nAgora, precisamos de um pouco de atenção: salvamos os argumentos numa lista e para usá-los na escala, usamos a função do.call(f,x), que faz uma chamada call à função f() usando os argumentos de x:\n\n```{r}\n#| label: coolest-plot-brewer\n\nggplot() +\n  geom_sf(\n    data = shp_mg_muni,\n    aes(fill = pop, color = pop)) +\n  do.call(scale_fill_fermenter, scale_args) +\n  do.call(scale_color_fermenter, scale_args) +\n  labs(\n    title = \"População dos municípios mineiros em 2021\",\n    caption = \"Fonte: IBGE (2023)\"\n  ) +\n  theme_void()\n```\n\n\n\n\n\n\n\nMapa de municípios e ferrovias\n\n```{r}\n#| label: ferro-plot\n\nshp_br &lt;- read_state(showProgress = F)\n```\n\nUsing year 2010\n\n```{r}\n#| label: ferro-plot\n\nggplot() +\n  geom_sf(\n    data = shp_br %&gt;% filter(abbrev_state != \"MG\"),\n    fill = \"grey85\",\n    color = \"grey60\"\n  ) +\n  geom_sf(\n    data = shp_mg_muni,\n    fill = \"grey95\",\n    color = \"grey90\"\n  ) + \n  geom_sf(\n    data = shp_ferrovias %&gt;% filter(Name %in% c(\"BH - Nova Era\", \"Nova Era - Pedro Nolasco\")),\n    aes(color = \"EFVM\", linetype = \"Operando\")\n  ) +\n  geom_sf(\n    data = shp_ferrovias %&gt;% filter(Name %in% c(\"Horto - Salvador\", \"Corinto - Pirapora\")),\n    aes(color = \"FCA\", linetype = \"Operando\")\n  ) +\n  geom_sf(\n    data = shp_ferrovias %&gt;% filter(Name == \"Horto - Itabirito\"),\n    aes(color = \"FdA\", linetype = \"Obra abandonada\")\n  ) +\n  geom_sf(\n    data = shp_ferrovias %&gt;% filter(Name == \"Itabirito - Rio\"),\n    aes(color = \"FdA\", linetype = \"Operando\")\n  ) +\n  scale_color_manual(\n    values = c(\"EFVM\" = \"#3cc954\", \"FCA\" = \"#60a8f6\", \"FdA\" = \"#2a4ea1\"),\n    name = \"Ferrovia\"\n  ) +\n  scale_linetype_manual(\n    values = c(\"Operando\" = \"solid\", \"Obra abandonada\" = \"dashed\"),\n    name = \"Status\"\n  ) +\n  labs(\n    title = \"Minas Gerais: algumas ferrovias\"\n  ) +\n  geom_sf_text(\n    data = shp_mg_muni %&gt;% filter(code_muni %in% c(3106200, 3136702, 3127701, 3143302)),\n    aes(label = name_muni),\n    hjust = 1,\n    size = 2.5\n  ) +\n  xlim(-50.75, -40.25) +\n  ylim(-22.75, -14.5) +\n  theme_void() +\n  theme(\n    panel.background = element_rect(fill = \"skyblue\", color = NA)\n  )\n```\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data"
  },
  {
    "objectID": "posts/2023-09-26-geoceps/index.html",
    "href": "posts/2023-09-26-geoceps/index.html",
    "title": "Geolocalizando CEPs",
    "section": "",
    "text": "Passo a passo para geolocalizar CEPs. Aqui vamos usar o pacote {mapsapi} do Google. Outra possibilidade é o {cepR} (CepAberto), mas tem um limite muito baixo de requisições por dia e, na minha experiência, é menos preciso. Tem ainda o {osmdata} (Open Street Map), mas o uso é um pouco mais complicado.\nO exemplo parte da RAIS, mas qualquer outra base pode ser usada. Cada API tem sua vantagem e desvantagem, mas a rotina geral é a mesma: preparar a base &gt; submeter a busca (query) &gt; salvar os dados &gt; carregar."
  },
  {
    "objectID": "posts/2023-09-26-geoceps/index.html#introdução",
    "href": "posts/2023-09-26-geoceps/index.html#introdução",
    "title": "Geolocalizando CEPs",
    "section": "",
    "text": "Passo a passo para geolocalizar CEPs. Aqui vamos usar o pacote {mapsapi} do Google. Outra possibilidade é o {cepR} (CepAberto), mas tem um limite muito baixo de requisições por dia e, na minha experiência, é menos preciso. Tem ainda o {osmdata} (Open Street Map), mas o uso é um pouco mais complicado.\nO exemplo parte da RAIS, mas qualquer outra base pode ser usada. Cada API tem sua vantagem e desvantagem, mas a rotina geral é a mesma: preparar a base &gt; submeter a busca (query) &gt; salvar os dados &gt; carregar."
  },
  {
    "objectID": "posts/2023-09-26-geoceps/index.html#setup",
    "href": "posts/2023-09-26-geoceps/index.html#setup",
    "title": "Geolocalizando CEPs",
    "section": "Setup",
    "text": "Setup\nCarregar os pacotes necessários\n\n```{r}\n#| label: setup\n#| message: false\n\nlibrary(tidyverse)\nlibrary(mapsapi)\nlibrary(here)\n```"
  },
  {
    "objectID": "posts/2023-09-26-geoceps/index.html#preparar-a-base-de-ceps",
    "href": "posts/2023-09-26-geoceps/index.html#preparar-a-base-de-ceps",
    "title": "Geolocalizando CEPs",
    "section": "Preparar a base de CEPs",
    "text": "Preparar a base de CEPs\nPartindo da RAIS, vamos pegar os CEPs que queremos buscar e deixá-los no formato necessário. Como a base é muito grande, isso pode levar um tempo.\nSupondo que a RAIS está em um arquivo único: leia-o e salve em um objeto. Aqui usamos a função read_fst(), substitua por read_csv(), readRDS() ou a função apropriada para o seu tipo de arquivo.\n\n\n\n\n\n\n\n\n\n\nPara evitar a confusão de diretórios envolvendo setwd()/getwd() e a inversão de barras, recomendo criar um R Project. Ele já considera que todos os seus diretórios são relativos à pasta principal do projeto, assim, todos os diretórios podem ser relativos a ele. Ex.: read_csv(\"data/rais.csv\") em vez de read_csv(\"C:/Documents/User/Projects/trabalho/data/rais.csv\").\nÉ bom ainda usar a função here() do pacote homônimo para garantir que o diretório será lido corretamente, principalmente quando se usar RMarkdown (.Rmd)/Quarto (.qmd), mas também nos scripts .R, como no exemplo abaixo.\n\n\n\n```{r}\n#| label: load-rais\n\ndf_estab &lt;- fst::read_fst(here(\"data/db/df_rais_estab.fst\"))\n```\n\nAgora, vamos filtrar essa base para excluir os CEPs duplicados e remover as outras informações, não vamos precisar delas agoras. Com isso, vamos gerar uma base de CEPs. O procedimento é o seguinte:\n\nPrimeiro, selecionamos só a variável que contém o cep (no meu caso, cep).\nIsso não é obrigatório, mas ajuda: modificamos (usando mutate()) a variável cep de duas formas,\n\n\nprimeiro, removendo o hífen, se houver\nsegundo, padronizando o CEP como uma variável do tipo character com 8 caracteres. No caso dos CEPs de SP Capital, um cuidado adicional: como eles começam com um zero à esquerda, se cep estivesse antes no formato de número, inserimo-lo novamente com a função str_pad().\n\n\nPassamos a função distinct() para remover duplicados.\nSalvamos na pasta adequada e com nome legível para usar depois.\n\n\n\n\n\n\n\n\n\n\n\n\nSalve essa base na sua pasta de dados para usar novamente se precisar, principalmente se a API travar\nUse um formato como o .RDS ou o .fst, que ocupam menos espaço e tem leitura mais rápida. Aqui, vamos usar o .RDS para já salvar direto no formato de vetor, que vamos precisar lá na frente.\n\n\n\n\n```{r}\n#| label: filter-ceps\n\ndf_ceps &lt;- df_estab %&gt;% \n  select(cep) %&gt;% \n  mutate(cep = str_remove(cep, \"-\")) %&gt;% \n  mutate(cep = str_pad(as.character(cep), width = 8, side = \"left\", pad = 0)) %&gt;% \n  distinct()\n\n# transformar em vetor\ndf_ceps &lt;- df_ceps$cep %&gt;% as.vector()\n\n# salvar\ndf_ceps %&gt;% saveRDS(here(\"data/db/df_ceps.RDS\"))\n```"
  },
  {
    "objectID": "posts/2023-09-26-geoceps/index.html#configurar-a-api",
    "href": "posts/2023-09-26-geoceps/index.html#configurar-a-api",
    "title": "Geolocalizando CEPs",
    "section": "Configurar a API",
    "text": "Configurar a API\nAgora, selecionamos a API desejada e fazemos a query. O {mapsapi} é minha escolha favorita para esse tipo de tarefa porque contém as informações mais precisas e é fácil de usar depois que você configura a chave.\nPrimeiro, crie um projeto no Google Cloud. Se você não sabe fazer isso, veja meu passo a passo no post Acessando a Base dos Dados no R.\nDepois disso, vá ao console do seu projeto, clique em APIs e serviços, depois em credenciais e crie uma chave API, como na imagem abaixo.\n\nVocê vai ver um alerta do google informando que sua API não está restrita: isso significa que qualquer um que tiver acesso a ela pode usá-la livremente (e cobrar no seu cartão de crédito). Eu recomendo que, no mínimo, você restrinja a API aos serviços que vai usar. Clique no nome dela para editá-la e defina as restrições, eu selecionei 16 serviços:\n\n\n\n\n\n\n\n\n\n\n\nUpdate 2023-10-23: Garanta que no mínimo duas APIs foram selecionadas, a Geocoding API e a Geolocation API (créditos ao @sirtheusrey por notar que eu esqueci de mencionar isso)\n\n\nAssim que tiver a sua API, copie a sua chave. Atenção: NUNCA compartilhe a sua chave com ninguém. Não faça upload de nenhum script que contenha sua chave! Assim que usá-la, recomendo apagar do script. Ou, melhor ainda, salve no .Renviron."
  },
  {
    "objectID": "posts/2023-09-26-geoceps/index.html#geocodificar-os-ceps",
    "href": "posts/2023-09-26-geoceps/index.html#geocodificar-os-ceps",
    "title": "Geolocalizando CEPs",
    "section": "Geocodificar os CEPs",
    "text": "Geocodificar os CEPs\nVou apresentar aqui três formas de geocodificar os CEPs. Elas são quase idênticas, a diferença é que na primeira buscamos todos os CEPs direto, na segunda usamos uma função para “tentar” o resultado e na terceira fazemos isso aos poucos. A vantagem é reduzir o retrabalho: na primeira alternativa, se der erro, temos que voltar do começo e buscar tudo de novo. Na segunda, se der problema, temos que refazer apenas os problemáticos. A terceira é uma camada a mais de proteção: se por exemplo a sua internet cair no meio do processo, você já tem os resultados salvos para parte dos dados.\n\nAlternativa 1: tudo de uma vez\nUsamos a função mp_geocode para geocodificação do {mapsapi}. Ela tem dois argumentos principais: (i) key, a chave API (podemos colocá-la direto na função ou salvar por fora, como abaixo) e (ii) addresses, que são os endereços que queremos geolocalizar. A função tem um argumento postcode, mas não vamos usá-lo: ele serve para limitar os endereços postais dos endereços, como nossos addresses já são CEPs, não faz sentido usar. O outro argumento que usamos, timeout, é o tempo limite (em segundos) que definimos para a API tentar buscar o CEP. Se passar esse tempo e não funcionar, ela desiste e passa para o próximo.\n\nNota: neste e nos chunks abaixo, estou usando message: false para ocultar minha chave API.\n\n\n```{r}\n#| label: geocode-v1\n#| message: false\n\n# chave API\nmapsapi_key &lt;- \"sua chave API\"\n## ou, usando .Renviron:\nmapsapi_key &lt;- Sys.getenv(\"mapsapi_key\")\n\n# query\n## obs.: aqui selecionei só os 2 primeiros para exemplo\nquery_ceps &lt;- mp_geocode(\n  addresses = df_ceps[1:2],\n  key = mapsapi_key,\n  timeout = 11\n  )\n```\n\n05724005................................OK\n04570001................................OK\n\n\nDepois disso, usamos mp_get_points() para obter o centroide do CEP. A função faz isso a partir de todos os endereços cadastrados no Google com esse CEP —ou seja, não reflete exatamente toda a área do CEP— mas é uma boa aproximação. Em seguida, salvamos em um objeto na pasta adequada e podemos (de preferência, em outro script) carregar para casar com a base da RAIS.\n\n\n\n\n\n\n\n\n\n\nEmbora o formato .fst tenha a melhor compressão de todas, ele não funciona com objetos espaciais. Por isso, salvamos no formato .RDS, que também é muito bom.\n\n\n\n```{r}\n#| label: geocode-ceps\n\n# pegar o centroide\nshp_ceps &lt;- mp_get_points(query_ceps)\n\n# salvar\nshp_ceps %&gt;% saveRDS(here(\"data/shp/shp_ceps.RDS\"))\n```\n\n\n\nAlternativa 2: safely\nAqui, vamos usar a função safely(): como explicado nesse excelente post do curso-r, essa função serve para tentar rodar um código e, quando der erro, ela salva o erro em uma lista em vez de parar tudo. Passo a passo:\n\nCriar uma função wrapper (i.e., “que embrulha”) para mp_geocode() e mp_get_points(). Essa função deve ter só um argumento: a base de dados. A chave e o timeout devem ser definidos dentro dela.\nPassar a base de CEPs na função que criamos, safely()\n\n\nIsso envolve usar a função map() para mapear os dados na função.\nEm seguida, transpomos os dados com transpose() para obter uma lista com duas sublistas: os resultados e os erros. Cada sublista tem ainda uma lista para cada resultado. É lista demais mas respire fundo, vai dar tudo certo.\n\n\nSelecionar só a lista de resultados e juntar tudo em um dataframe só com bind_rows()\nSalvar em um objeto na pasta adequada. Esse objeto terá duas classes: data.frame e sf, ou Simple Feature, que é a classe dos objetos espaciais.\n\n\n```{r}\n#| label: geocode-v2\n#| message: false\n\n# chave API\nmapsapi_key &lt;- \"sua chave API\"\n## ou, usando .Renviron:\nmapsapi_key &lt;- Sys.getenv(\"mapsapi_key\")\n\n# função envelope\ngeoceps &lt;- function(data) {\n  mp_geocode(addresses = data, key = mapsapi_key, timeout = 11) %&gt;% \n    mp_get_points()\n}\n\n# novamente: selecionando só 5 para exemplificar e adicionei um erro de propósito\nquery_ceps &lt;- df_ceps[1:5] %&gt;% map(safely(geoceps)) %&gt;% transpose()\n\n# puxar só os resultados\nshp_ceps &lt;- query_ceps$result %&gt;% bind_rows()\n\n# salvar \nshp_ceps %&gt;% saveRDS(here(\"data/shp/shp_ceps.RDS\"))\n```\n\n05724005................................OK\n04570001................................OK\n11721100................................OK\n03311000................................OK\n05615190................................OK\n\n\nVisualizando os resultados:\n\n```{r}\n#| label: view-ceps\n\n# conferir a classe\nclass(shp_ceps)\n\n# usando kable para visualização limpa no arquivo final\nshp_ceps %&gt;% \n  knitr::kable()\n```\n\n[1] \"sf\"         \"data.frame\"\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nstatus\naddress\naddress_google\nlocation_type\npnt\n\n\n\n\n1\nOK\n05724005\nAv. Giovanni Gronchi, 6633-2147483647 - Vila Andrade, São Paulo - SP, 05724-005, Brazil\nAPPROXIMATE\nPOINT (-46.73669 -23.63962)\n\n\n1\nOK\n04570001\nAv. Nova Independência, 552-2147483647 - Brooklin, São Paulo - SP, 04570-001, Brazil\nAPPROXIMATE\nPOINT (-46.6888 -23.6008)\n\n\n1\nOK\n11721100\nVila Antartica, Praia Grande - SP, 11721-100, Brazil\nAPPROXIMATE\nPOINT (-46.45468 -24.01176)\n\n\n1\nOK\n03311000\nR. Apucarana, 1-1000 - Tatuapé, São Paulo - SP, 03311-000, Brazil\nAPPROXIMATE\nPOINT (-46.56427 -23.54278)\n\n\n1\nOK\n05615190\nRua dos Três Irmãos - Vila Progredior, São Paulo - SP, 05615-190, Brazil\nAPPROXIMATE\nPOINT (-46.7165 -23.58819)\n\n\n\n\n\n\n\nAlternativa 3: por partes, safely\nNa alternativa 2, já evitamos um bocado de retrabalho impedindo que a função pare se encontrar um erro. Agora, vamos facilitar ainda mais a nossa vida: para evitar que um apagão, queda de internet etc apague todo o seu trabalho, vamos dividir tudo em etapas e ir salvando aos poucos. O procedimento é parecido, mas vamos usar e abusar da função map():\n\nPartir o data frame em chunks (pedaços) menores. Eu sugiro ir de 5 mil em 5 mil; aqui no exemplo, vamos de 5 em 5 para os 17 primeiros dados. Para isso:\n\n\nA função split() vai partir os dados\nDentro de split, seq_along(data) é uma sequência ao longo dos dados.\nDividimo-la pelo tamanho máximo do chunk e depois arredondamos para cima com ceiling()\nIsso vai criar uma lista com \\(n\\) sublistas, em que \\(n\\) é o número de chunks.\n\n\nCriar uma função wrapper parecida com a do passo anterior, mas atentando para o fato de que agora temos que mapear a lista nas funções.\n\n\nNota: dentro de map, usamos a sintaxe das funções anônimas, \\(coiso) trem(coiso). No nosso caso, o \\(x) é cada chunk de ceps da lista.\n\n\nAgora usamos a imap() uma variação de map() que permite dar nome aos bois.\n\n\nEla pede dois argumentos, que eu chamei de x e y; no caso, y é o identificador. Vamos usá-lo para salvar os chunks no padrão shp_ceps_1.RDS, shp_ceps_2.RDS, …, shp_ceps_n.RDS.\nEm vez do cifrão, puxamos result usando a função pluck(). Ela permite fazer tudo de uma vez, sem quebrar o fluxo.\n\n\n```{r}\n#| label: geocode-v3\n#| message: false\n\n# definindo os chunks\nchunk_max &lt;- 5\n\ndf_ceps &lt;- df_ceps[1:17] %&gt;% \n  split(ceiling(seq_along(df_ceps[1:17])/chunk_max))\n\n# chave API\nmapsapi_key &lt;- Sys.getenv(\"mapsapi_key\")\n\n# função envelope\ngeoceps &lt;- function(data) {\n  data %&gt;% \n    map(\n      \\(x)\n      mp_geocode(addresses = x,key = mapsapi_key, timeout = 11) %&gt;% \n        mp_get_points()\n    )\n}\n\nquery_ceps &lt;- df_ceps %&gt;% \n  imap(\n    \\(x, y)\n    map(x, safely(geoceps)) %&gt;% \n      transpose() %&gt;% \n      pluck(\"result\") %&gt;% \n      bind_rows() %&gt;% \n      saveRDS(here(paste0(\"data/shp/shp_ceps_\", y, \".RDS\")))\n  )\n```\n\nWarning in min(bb[, 1L], na.rm = TRUE): no non-missing arguments to min;\nreturning Inf\n\n\nWarning in min(bb[, 2L], na.rm = TRUE): no non-missing arguments to min;\nreturning Inf\n\n\nWarning in max(bb[, 3L], na.rm = TRUE): no non-missing arguments to max;\nreturning -Inf\n\n\nWarning in max(bb[, 4L], na.rm = TRUE): no non-missing arguments to max;\nreturning -Inf\n\n\n05724005................................OK\n04570001................................OK\n11721100................................OK\n03311000................................OK\n05615190................................OK\n02034010................................OK\n01125000................................OK\n04814630................................OK\n03306030................................OK\n04551060................................OK\n04061003................................OK\n05316900................................ZERO_RESULTS\n05374050................................OK\n04365000................................OK\n02832160................................OK\n03053000................................OK\n01407200................................OK\n\n\nFinalmente, depois que você rodar a query por partes, podemos carregar os arquivos no R e montar de novo em um dataset só com nossos ceps. Para isso:\n\nvamos usar list.files() para listar todos os arquivos na pasta que seguem o padrão e mapear essa lista de padrões em readRDS() e, em sequência, bindar as rows. Detalhe importante: pattern é uma regex, ou regular expression. Nesse exemplos, estamos buscando o padrão que começa com shp_ceps_, seguido de um ou mais dígitos (\\\\d_) e do final .RDS (\\\\.RDS$).\nAgora é só mapear os arquivos.\n\n\n```{r}\n#| label: load-queries\n\npaths &lt;- list.files(\n  path = here(\"data/shp\"),\n  pattern = \"shp_ceps_\\\\d+\\\\.RDS$\",\n  full.names = T\n)\n\nshp_ceps &lt;- paths %&gt;% \n  map(readRDS) %&gt;% \n  bind_rows()\n\n# visualizando\nknitr::kable(shp_ceps)\n```\n\n\n\n\n\n\n\n\n\n\n\n\nid\nstatus\naddress\naddress_google\nlocation_type\npnt\n\n\n\n\n1\nOK\n05724005\nAv. Giovanni Gronchi, 6633-2147483647 - Vila Andrade, São Paulo - SP, 05724-005, Brazil\nAPPROXIMATE\nPOINT (-46.73669 -23.63962)\n\n\n1\nOK\n04570001\nAv. Nova Independência, 552-2147483647 - Brooklin, São Paulo - SP, 04570-001, Brazil\nAPPROXIMATE\nPOINT (-46.6888 -23.6008)\n\n\n1\nOK\n11721100\nVila Antartica, Praia Grande - SP, 11721-100, Brazil\nAPPROXIMATE\nPOINT (-46.45468 -24.01176)\n\n\n1\nOK\n03311000\nR. Apucarana, 1-1000 - Tatuapé, São Paulo - SP, 03311-000, Brazil\nAPPROXIMATE\nPOINT (-46.56427 -23.54278)\n\n\n1\nOK\n05615190\nRua dos Três Irmãos - Vila Progredior, São Paulo - SP, 05615-190, Brazil\nAPPROXIMATE\nPOINT (-46.7165 -23.58819)\n\n\n1\nOK\n02034010\nR. Alfredo Guedes - Santana, São Paulo - SP, 02034-010, Brazil\nAPPROXIMATE\nPOINT (-46.62484 -23.50629)\n\n\n1\nOK\n01125000\nR. da Graça, 2-2147483646 - Bom Retiro, São Paulo - SP, 01125-000, Brazil\nAPPROXIMATE\nPOINT (-46.64014 -23.52655)\n\n\n1\nOK\n04814630\nRua Caiuby Alves de Castro - Jardim Guanhembu, São Paulo - SP, 04814-630, Brazil\nAPPROXIMATE\nPOINT (-46.68125 -23.7305)\n\n\n1\nOK\n03306030\nR. Fernão Tavares - Cidade Mãe do Céu, São Paulo - SP, 03306-030, Brazil\nAPPROXIMATE\nPOINT (-46.57571 -23.54378)\n\n\n1\nOK\n04551060\nR. Funchal - Vila Olímpia, São Paulo - SP, 04551-060, Brazil\nAPPROXIMATE\nPOINT (-46.68952 -23.59411)\n\n\n1\nOK\n04061003\nAv. Itacira, 2311-2147483647 - Planalto Paulista, São Paulo - SP, 04061-003, Brazil\nAPPROXIMATE\nPOINT (-46.64444 -23.62447)\n\n\n1\nZERO_RESULTS\n05316900\nNA\nNA\nPOINT EMPTY\n\n\n1\nOK\n05374050\nR. Gertrudes Cunha - Jardim Ester Yolanda, São Paulo - SP, 05374-050, Brazil\nAPPROXIMATE\nPOINT (-46.75819 -23.57779)\n\n\n1\nOK\n04365000\nJardim Santo Antoninho, São Paulo - State of São Paulo, 04365-000, Brazil\nAPPROXIMATE\nPOINT (-46.66846 -23.65589)\n\n\n1\nOK\n02832160\nR. Col. Fernando Costa - Parque Sao Luis, São Paulo - SP, 02832-160, Brazil\nAPPROXIMATE\nPOINT (-46.69385 -23.48179)\n\n\n1\nOK\n03053000\nR. Bresser, 1051-1800 - Brás, São Paulo - SP, 03053-000, Brazil\nAPPROXIMATE\nPOINT (-46.60735 -23.54164)\n\n\n1\nOK\n01407200\nAv. Nove de Julho, 4701-2147483647 - Jardim Paulista, São Paulo - SP, 01407-200, Brazil\nAPPROXIMATE\nPOINT (-46.67088 -23.57679)"
  },
  {
    "objectID": "posts/2023-09-26-geoceps/index.html#bônus-background-jobs",
    "href": "posts/2023-09-26-geoceps/index.html#bônus-background-jobs",
    "title": "Geolocalizando CEPs",
    "section": "Bônus: background jobs",
    "text": "Bônus: background jobs\nQuando você estiver geolocalizando vários CEPs, isso vai demorar bastante —talvez uma tarde inteira, talvez mais. Por isso, é útil executar como um background job: isso libera o seu R para você fazer outras coisas enquanto ele roda a API em outra seção. Só não se esqueça de verificar de vez em quando o background job para ver se tá rodando, ao menos logo que você executar. Felizmente, usando safely() a chance de um erro travar tudo diminui muito. O que eu gosto de fazer: executar como background job, dormir, acordar e admirar a base que baixou à noite.\nPara fazer um background job, temos que salvar o código dentro de um script R. Ou seja: não funciona com markdown (.Rmd/.qmd). Quando tiver seu script pronto, é só ir em Background Jobs, provavelmente na parte de baixo do seu RStudio, perto do console.\n\nDepois que você iniciar o background job, é só ir acompanhando ali:\n\nNo final, ele te avisa se deu certo. E é isso!"
  },
  {
    "objectID": "posts/2023-06-21-abnquarto-v0/index.html",
    "href": "posts/2023-06-21-abnquarto-v0/index.html",
    "title": "abnquarto",
    "section": "",
    "text": "Já vou avisando: a próxima seção é uma apologia ao Quarto e por que você deve abandonar o processador de texto do Bill Gates. Se não quiser ler essa groselha, pula direto para a parte em que eu ensino como usar o abnquarto"
  },
  {
    "objectID": "posts/2023-06-21-abnquarto-v0/index.html#sec-tldr",
    "href": "posts/2023-06-21-abnquarto-v0/index.html#sec-tldr",
    "title": "abnquarto",
    "section": "",
    "text": "Já vou avisando: a próxima seção é uma apologia ao Quarto e por que você deve abandonar o processador de texto do Bill Gates. Se não quiser ler essa groselha, pula direto para a parte em que eu ensino como usar o abnquarto"
  },
  {
    "objectID": "posts/2023-06-21-abnquarto-v0/index.html#sec-intro",
    "href": "posts/2023-06-21-abnquarto-v0/index.html#sec-intro",
    "title": "abnquarto",
    "section": "Groselhas preliminares",
    "text": "Groselhas preliminares\n\nPor que Quarto\nEscrever resenhas, artigos ou até mesmo sua tese no R pode parecer impossível, loucura ou falta do que fazer. Talvez esta última afirmação seja verdade, mas as duas primeiras, certamente não.\nComecei a escrever pela IDE do RStudio desde que comecei a aprender R pelo Codecademy… Mas quando fui tentar compilar um PDF, o bicho pegou: instalar um compilador , uma hora pra entender como muda as margens, três horas para descobrir como coloca recuo no primeiro parágrafo… a lista de perrengues é interminável, mas o meu objetivo aqui é encorajar as pessoas a usarem Quarto, e não o contrário!\nConsiderando essa curva de aprendizado, por que vale a pena aprender a escrever em Quarto? E porque não direto em no Overleaf ou outro editor? A minha resposta passa por quatro pontos: consistência, reprodução, treino e estética. Em primeiro lugar, a consistência de um editor WYSIWYM (what you see is what you mean), como Markdown ou , é incomparável com a de editores WYSIWYG (what you see is what you get). Isso acontece porque no segundo grupo de editores, da filosofia “clicar no botão”, você pode estar perdido, sair fuçando e por acaso dar certo… Mas depois, a chance de você não saber o que fez e ficar tudo desconfigurado é considerável. Já nos editores em que o resultado deve ser programado, o comando X sempre vai levar a Y; é mais fácil padronizar.\nMas então por que Quarto e não ? Aí entramos no segundo argumento, o da reprodução. Quando sua análise estatística já foi feita toda em R, fica muito fácil integrar os resultados com um relatório final, misturando tabelas e gráficos programados e texto. Sinceramente, eu acho um inferno transferir tabela e gráfico para o Word; e não importa o que eu faça, ainda não descobri um jeito de evitar perda de qualidade na hora de compilar para PDF. Uma tabela programada via kableExtra() vai te dar trabalho no começo, mas depois que sai, vale a pena. Outra situação em que vale a pena escrever em Quarto é exatamente esta: misturar código e texto, montar uma aula, um tutorial, fazer uma lista de econometria. Mas ainda assim… Por que Quarto Markdown e não RMarkdown? Ora, é muito simples. Por acaso fazia sentido ser alfabetizado com o acordo ortográfico antigo no ano em que o novo entrou em vigor? O Quarto é a evolução do RMarkdown. Tem muitas funcionalidades que não tinham no outro —eu pessoalmente gosto do YAML global, as configurações de chunk e os callouts. E se você ainda quiser usar um editor visual, they’ve got you covered! O quarto vem com um editor visual que é quase um word, para o desmame do mundo WYSIWYG doer menos.\nTerceiro ponto: treine suas habilidades de programação. Aí é pra maluco mesmo, é pra quem gosta de encarar uma tela preta pra ver um monte de letra e número. Essa caixinha é legal demais, e se você gosta do quebra-cabeça, vai gostar de aprender Quarto. Em todos os casos, é um excelente treino de resolução de problemas! E talvez você acabe aprendendo um pouquinho de , html e css, se quiser customizar seu material…\nO que me leva ao quarto motivo: é bonito demais! A vida é muito curta para coisas feias, e eu pessoalmente gosto muito do resultado de um arquivo compilado em Quarto, Rmarkdown, Xaringan, Revealjs ou Shiny. O céu é o limite! Quanto mais eu aprendo, mais eu gosto. E o importante é ser feliz!\n\n\nPor que abnquarto\nSe você já se convenceu a escrever em Quarto, talvez se depare com o mesmo desafio que eu: entrar na caixinha da ABNT. Tem regra de margem, regra de recuo, regra de fonte, disso, daquilo… É um parto e é muito chato, até no Word. Por isso, é bom ter algumas configurações predefinidas para o documento sair no formato exigido pelas nossas instituições patrícias. É um template bem simples, longe de ser um pacote completo, mas já é uma mão na roda!"
  },
  {
    "objectID": "posts/2023-06-21-abnquarto-v0/index.html#sec-firststeps",
    "href": "posts/2023-06-21-abnquarto-v0/index.html#sec-firststeps",
    "title": "abnquarto",
    "section": "Primeiros passos",
    "text": "Primeiros passos\n\nComo baixar\n\nAlternativa 1\nBaixar tudo e inserir manualmente no seu computador: &lt;&gt; Code &gt; Download ZIP\n\n\nAlternativa 2\nBasta clonar este repositório, copiando o link acima.\nPelo Terminal (do RStudio ou do seu computador):\ngit clone https://github.com/baarthur/abnquarto.git nome_da_pasta\n\nDica: Garanta que você está na pasta certa usando o comando pwd (print work directory); caso contrário, digite cd e o caminho da pasta onde vai ficar o projeto.\n\nIsso vai criar uma pasta no diretório que você excolheu com os arquivos necessários. Os mais importantes são _quarto.yml (definições globais de margens, recuos, bibliografia etc) e tudo na pasta src, onde há um template e os arquivos necessários na subpasta yaml.\n\n\n\nUso básico\n\nEdite o arquivo _quarto.yml seguindo as instruções do arquivo.\nUse o template em src (ou crie um arquivo do zero onde quiser) —veja aqui como fica o template.\n\nLinks úteis:\n\nGuias do Quarto\nOpções para o formato html\nOpções para o formato pdf\nGitHub + R\nCriando sites com Quarto\nTabelas para pdf usando kableExtra"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Arthur Bazolli Alvarenga",
    "section": "",
    "text": "Mestrando em Economia na UFJF\nApaixonado por cidades e mobilidade, pesquiso economia regional e urbana e economia do trabalho, em especial economias de aglomeração, acessibilidade, uso do solo e mercados de trabalho locais."
  },
  {
    "objectID": "index.html#formação",
    "href": "index.html#formação",
    "title": "Arthur Bazolli Alvarenga",
    "section": "Formação",
    "text": "Formação\nUniversidade Federal de Juiz de Fora (UFJF) | Juiz de Fora, Brasil Mestrado em Economia Aplicada | Março de 2022 - presente\nIbmec | Belo Horizonte, Brasil Graduação em Economia | Fevereiro de 2017 - dezembro de 2021"
  },
  {
    "objectID": "index.html#experiênca",
    "href": "index.html#experiênca",
    "title": "Arthur Bazolli Alvarenga",
    "section": "Experiênca",
    "text": "Experiênca\nUFJF | Assistante de pesquisa | Março de 2023 - presente\nUFJF | Estágio docência | Outubro de 2022 - fevereiro de 2023\nImpacto Hub | Analista de M&A | Novembro de 2019 - março de 2021"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "30 day Map Challenge 2023\n\n\n\nR\n\n\nr-spatial\n\n\nGeocomputação\n\n\nTutorial\n\n\n\nCode and ramblings\n\n\n\nArthur Bazolli Alvarenga\n\n\n5 de nov. de 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGeolocalizando CEPs\n\n\n\nR\n\n\nr-spatial\n\n\nGeocomputação\n\n\nTutorial\n\n\n\nA partir dos dados da RAIS\n\n\n\nArthur Bazolli Alvarenga\n\n\n26 de set. de 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nabnquarto\n\n\n\nR\n\n\nQuarto\n\n\nABNT\n\n\nTutorial\n\n\n\nMonte seu Quarto em ABNT\n\n\n\nArthur Bazolli Alvarenga\n\n\n23 de jun. de 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRotina espacial no R\n\n\n\nR\n\n\nr-spatial\n\n\nGeocomputação\n\n\nTutorial\n\n\n\nAprenda a baixar, filtrar e combinar dados\n\n\n\nArthur Bazolli Alvarenga\n\n\n21 de jun. de 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAcessando a Base dos Dados no R\n\n\n\nR\n\n\nBasedosdados\n\n\nTutorial\n\n\n\nÉ mais fácil do que parece!\n\n\n\nArthur Bazolli Alvarenga\n\n\n20 de jun. de 2023\n\n\n\n\n\n\n\n\nNenhum item correspondente"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Material",
    "section": "",
    "text": "Notas de aula, trabalhos em andamento e mais\n\n\n\nEquilíbrio da estrutura intraurbana\n\nApresentação\nNotas de aula\n\n\n\n\n\n\nReal estate and rapid transit: estimating the market premium of the São Paulo Rail Network\n\nApresentado no XX Enaber (Salvador, Brasil) e no 50º Encontro Nacional de Economia (Fortaleza, Brasil)\nVersão atual (inglês)\nVersão em português\nApresentação (português)\n\nHeritage Tourism and Economic Development: An Input-Output Analysis for Minas Gerais, Brazil\n\nApresentando no 29th IIOA (Alghero, Itália) em junho de 2023\nVersão atual (inglês)\nApresentação (inglês)\n\n\n\n\n\n\n{spatialops}: Operações espaciais e outras ferramentas úteis\n\nGitHub repo\n\nabnquarto: um template em Quarto nas normas da ABNT\n\nGitHub repo\nExemplo"
  },
  {
    "objectID": "resources.html#eco075-2022---economia-urbana-1",
    "href": "resources.html#eco075-2022---economia-urbana-1",
    "title": "Material",
    "section": "",
    "text": "Equilíbrio da estrutura intraurbana\n\nApresentação\nNotas de aula"
  },
  {
    "objectID": "resources.html#trabalhos-em-andamento",
    "href": "resources.html#trabalhos-em-andamento",
    "title": "Material",
    "section": "",
    "text": "Real estate and rapid transit: estimating the market premium of the São Paulo Rail Network\n\nApresentado no XX Enaber (Salvador, Brasil) e no 50º Encontro Nacional de Economia (Fortaleza, Brasil)\nVersão atual (inglês)\nVersão em português\nApresentação (português)\n\nHeritage Tourism and Economic Development: An Input-Output Analysis for Minas Gerais, Brazil\n\nApresentando no 29th IIOA (Alghero, Itália) em junho de 2023\nVersão atual (inglês)\nApresentação (inglês)"
  },
  {
    "objectID": "resources.html#r-1",
    "href": "resources.html#r-1",
    "title": "Material",
    "section": "",
    "text": "{spatialops}: Operações espaciais e outras ferramentas úteis\n\nGitHub repo\n\nabnquarto: um template em Quarto nas normas da ABNT\n\nGitHub repo\nExemplo"
  }
]